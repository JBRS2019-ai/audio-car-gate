<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<title>Teachable Machine Audio ‚Äì Minimal</title>

<!-- Use the versions shown in TM's README for audio exports -->
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.3.1/dist/tf.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/speech-commands@0.4.0/dist/speech-commands.min.js"></script>

<style>
  html,body{margin:0;height:100%;display:grid;place-items:center;background:#e0551b;color:#fff;font:16px/1.4 system-ui,Segoe UI,Roboto,Arial}
  button{border:0;border-radius:12px;padding:12px 16px;font-weight:700;background:#fff;color:#e0551b;cursor:pointer}
  #status{margin-top:12px;font-weight:800}
</style>
</head>
<body>

<button id="start">üéôÔ∏è Start Listening</button>
<div id="status">Idle</div>
<div id="labels"></div>

<script>
  // --- Your TM Audio model (hosted) ---
  const MODEL_BASE = "https://teachablemachine.withgoogle.com/models/fww4C8ATZ/"; // or take from ?model=
  const PROB_THRESHOLD = 0.75;          // tweak as needed
  const OVERLAP = 0.50;                 // 0.5‚Äì0.75 is typical
  const SEND_SUFFIX = "\n";             // for micro:bit UART lines

  // Optional: map class names to custom UART strings
  const MAP_TO_UART = {}; // e.g. { "Auto": "Auto", "Geenauto": "Geenauto" }

  const $ = s => document.querySelector(s);
  const setStatus = t => $("#status").textContent = t;

  let recognizer, labels, lastLabel = "";

  async function createModel() {
    const checkpointURL = MODEL_BASE + "model.json";
    const metadataURL   = MODEL_BASE + "metadata.json";

    const rec = speechCommands.create(
      "BROWSER_FFT",    // required
      undefined,        // not used for custom TM models
      checkpointURL,
      metadataURL
    );
    await rec.ensureModelLoaded();
    return rec;
  }

  function uartSend(s) {
    if (typeof sendUART === "function") sendUART(String(s) + SEND_SUFFIX);
    else console.log("UART:", s);
  }

  async function startListening(){
    try {
      setStatus("Loading model‚Ä¶");
      recognizer = await createModel();
      labels = recognizer.wordLabels(); // class names

      // show labels
      const box = $("#labels");
      box.innerHTML = "";
      labels.forEach(()=> box.appendChild(document.createElement("div")));

      setStatus("Listening‚Ä¶ allow microphone");
      recognizer.listen(result => {
        // result.scores is an array aligned with labels[]
        const scores = result.scores;
        let topIdx = 0;
        for (let i=1; i<scores.length; i++) if (scores[i] > scores[topIdx]) topIdx = i;

        // render all scores
        for (let i=0; i<labels.length; i++) {
          box.childNodes[i].textContent = `${labels[i]}: ${scores[i].toFixed(2)}`;
        }

        const topLabel = labels[topIdx];
        const topProb  = scores[topIdx];

        setStatus(`${topLabel} (${(topProb*100).toFixed(0)}%)`);

        // send only when confident AND label changed
        if (topProb >= PROB_THRESHOLD && topLabel !== lastLabel) {
          const cmd = (topLabel in MAP_TO_UART) ? MAP_TO_UART[topLabel] : topLabel;
          uartSend(cmd);
          lastLabel = topLabel;
        }

      }, {
        includeSpectrogram: true,
        probabilityThreshold: PROB_THRESHOLD,
        invokeCallbackOnNoiseAndUnknown: true,
        overlapFactor: OVERLAP
      });

      // To stop later: recognizer.stopListening();
    } catch (err) {
      console.error(err);
      alert("Could not start audio model: " + (err.message || "see console"));
      setStatus("Error");
    }
  }

  $("#start").addEventListener("click", startListening);
</script>
</body>
</html>
